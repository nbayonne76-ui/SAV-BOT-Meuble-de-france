# üìä RAPPORT D'ANALYSE DE SCALABILIT√â - CHATBOT SAV MEUBLE DE FRANCE

**Date:** 6 D√©cembre 2025
**Version:** 1.0
**Objectif:** √âvaluer la capacit√© du chatbot √† g√©rer 200 demandes/mois aujourd'hui et 400+ demandes/mois dans 2-3 ans

---

## üéØ R√âSUM√â EX√âCUTIF

### Capacit√© Actuelle
- ‚úÖ **Fonctionnel** pour 200 demandes/mois (~6-7 demandes/jour)
- ‚ö†Ô∏è **Limitations critiques** identifi√©es pour la mont√©e en charge
- üî¥ **Refonte n√©cessaire** pour atteindre 400 demandes/mois de mani√®re fiable

### Verdict Global
**Le syst√®me actuel peut g√©rer 200 demandes/mois MAIS n√©cessite des am√©liorations MAJEURES pour passer √† 400 demandes/mois de mani√®re robuste et maintenable.**

---

## 1Ô∏è‚É£ ANALYSE DE CAPACIT√â ACTUELLE

### Architecture Actuelle

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend      ‚îÇ  React + Vite (Port 5173)
‚îÇ   (Vite)        ‚îÇ  - Interface chat conversationnelle
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  - Communication vocale bidirectionnelle
         ‚îÇ           - Upload photos/vid√©os
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Backend       ‚îÇ  FastAPI + Uvicorn (Port 8000)
‚îÇ   (FastAPI)     ‚îÇ  - API REST
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  - Gestion sessions en m√©moire (dict)
         ‚îÇ           - Workflow SAV automatis√©
         ‚îÇ
         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ OpenAI GPT-4 (API externe)
         ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Stockage EN M√âMOIRE (‚ö†Ô∏è CRITIQUE)
                     - Tickets SAV: sav_workflow_engine.active_tickets
                     - Sessions chat: chatbot_instances
                     - Aucune persistance
```

### M√©triques de Performance Estim√©es

#### Volume Actuel (200 demandes/mois)
- **6-7 demandes par jour** en moyenne
- **~1 demande toutes les 2-3 heures** (8h-20h)
- **Pics possibles:** 15-20 demandes/jour (soldes, promotions)

#### Charge Serveur par Demande
1. **Conversation initiale:** ~3-5 messages
2. **Validation ticket:** 2 messages
3. **Total:** ~5-7 messages par demande SAV compl√®te

**Calcul de charge mensuelle:**
- 200 demandes √ó 6 messages = **1 200 messages OpenAI/mois**
- Temps moyen par message: 2-4 secondes
- Temps total conversation: 30-60 secondes par client

#### Co√ªts OpenAI Estim√©s (GPT-4)

**Prix GPT-4 (2025):**
- Input: $0.03 / 1K tokens
- Output: $0.06 / 1K tokens

**Estimation par conversation SAV:**
- Prompt syst√®me: ~800 tokens
- Message utilisateur moyen: ~100 tokens
- R√©ponse chatbot moyenne: ~300 tokens
- Total par √©change: ~1 200 tokens

**Co√ªt par demande SAV (6 messages):**
- Input: (800 + 100√ó6) √ó $0.03/1000 = $0.042
- Output: (300√ó6) √ó $0.06/1000 = $0.108
- **Total: ~$0.15 par demande SAV**

**Co√ªt mensuel actuel (200 demandes):**
- 200 demandes √ó $0.15 = **$30/mois**

**Co√ªt mensuel projet√© (400 demandes):**
- 400 demandes √ó $0.15 = **$60/mois**

### ‚úÖ Points Forts de l'Architecture Actuelle

1. **Interface Utilisateur Excellente**
   - Chat conversationnel intuitif
   - Communication vocale bidirectionnelle (Speech-to-Text + Text-to-Speech)
   - Upload de photos/vid√©os pour preuves
   - Navigation fluide Chat ‚Üî Dashboard

2. **Workflow SAV Automatis√© Intelligent**
   - D√©tection automatique du probl√®me (8 cat√©gories)
   - Analyse de priorit√© multi-facteurs (P0-P3)
   - V√©rification automatique de garantie
   - Collecte de preuves guid√©e
   - D√©cision automatique (r√©solution vs escalade)

3. **Validation Client Robuste**
   - R√©capitulatif avant cr√©ation ticket
   - Confirmation "OUI" obligatoire
   - Option continuation/cl√¥ture apr√®s ticket

4. **Analyse Avanc√©e**
   - D√©tection de ton et urgence (CALM, FRUSTRATED, ANGRY, CRITICAL)
   - Scoring de priorit√© bas√© sur multiples crit√®res
   - Analyse de garantie automatique

### ‚ö†Ô∏è Capacit√© Maximale Actuelle

**Avec l'architecture EN M√âMOIRE actuelle:**

| M√©trique | Valeur Estim√©e | Limite |
|----------|---------------|---------|
| Demandes simultan√©es | 5-10 | 20 max |
| Tickets stock√©s | 50-100 | 200 max |
| Sessions actives | 10-20 | 50 max |
| Uptime | 95% | Red√©marrage = perte totale |

**Capacit√© mensuelle r√©aliste:** 150-250 demandes maximum

---

## 2Ô∏è‚É£ RISQUES ET LIMITATIONS CRITIQUES

### üî¥ CRITIQUE - Niveau 1 (Bloquants pour 400 demandes/mois)

#### 1. Stockage EN M√âMOIRE (RISQUE MAJEUR ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è)

**Probl√®me:**
```python
# chat.py ligne 24
chatbot_instances = {}  # ‚ùå Dictionnaire en m√©moire

# sav_workflow_engine.py
class SAVWorkflowEngine:
    def __init__(self):
        self.active_tickets = {}  # ‚ùå Dictionnaire en m√©moire
```

**Cons√©quences:**
- ‚ùå **Red√©marrage serveur = PERTE TOTALE** de tous les tickets
- ‚ùå **Crash Python = PERTE TOTALE** de toutes les conversations
- ‚ùå **Aucune tra√ßabilit√©** apr√®s fermeture session
- ‚ùå **Impossible de g√©n√©rer des rapports** historiques
- ‚ùå **Pas de backup** automatique
- ‚ùå **Pas de reprise sur erreur**

**Impact √† 400 demandes/mois:**
- 13-14 demandes/jour
- Risque de perte de 5-10 tickets lors d'un red√©marrage
- Perte potentielle de donn√©es clients critiques

**Solution OBLIGATOIRE:** Migration vers base de donn√©es persistante (PostgreSQL/MySQL)

---

#### 2. Sessions Chatbot Non Persistantes

**Probl√®me:**
```python
# Ligne 84-86 chat.py
if request.session_id not in chatbot_instances:
    chatbot_instances[request.session_id] = MeubledeFranceChatbot(api_key=api_key)
```

**Cons√©quences:**
- ‚ùå Client d√©connect√© = conversation perdue
- ‚ùå Refresh navigateur = session r√©initialis√©e
- ‚ùå Load balancing impossible (session li√©e au serveur)
- ‚ùå Pas de reprise de conversation

**Solution:** Redis/Memcached pour sessions distribu√©es

---

#### 3. Absence de Gestion d'Erreurs Robuste

**Probl√®mes identifi√©s:**
- Pas de retry automatique sur √©chec OpenAI
- Pas de fallback si quota OpenAI √©puis√©
- Pas de file d'attente pour requ√™tes √©chou√©es
- Logging Unicode d√©faillant (erreurs emoji)

**Impact:** Perte de tickets SAV lors d'erreurs temporaires

---

#### 4. Co√ªts OpenAI Non Optimis√©s

**Probl√®me:**
- Utilisation de GPT-4 pour TOUS les messages (m√™me simples)
- Pas de cache pour r√©ponses communes
- Aucune limitation de tokens

**Impact financier √† 400 demandes/mois:**
- $60/mois avec GPT-4
- Potentiel $120-150/mois si conversations longues
- Pas de contr√¥le des co√ªts

**Solution:** Hybrid GPT-4 / GPT-3.5-turbo selon complexit√©

---

### üü† HAUTE PRIORIT√â - Niveau 2 (Limitations de performance)

#### 5. Architecture Monoserveur

**Probl√®me:**
- Un seul processus FastAPI
- Pas de load balancing
- Pas de failover

**Capacit√© maximale:** 30-50 requ√™tes simultan√©es

**Impact √† 400 demandes/mois:**
- Pics de trafic non g√©r√©s
- Temps de r√©ponse d√©grad√©
- Risque de timeout

---

#### 6. Aucune Mise en Cache

**Probl√®me:**
- Donn√©es commandes r√©cup√©r√©es √† chaque fois
- V√©rification garantie recalcul√©e
- Catalogue produits non cach√©

**Impact:**
- 3-5 secondes par v√©rification
- Charge inutile sur services externes

---

#### 7. S√©curit√© et Authentification Basiques

**Probl√®mes:**
- Pas d'authentification utilisateur
- Pas de rate limiting
- Pas de protection CSRF
- Cl√© API stock√©e en clair dans .env

**Risques:**
- Abus du syst√®me
- D√©passement quota OpenAI par attaque
- Vol de donn√©es clients

---

### üü° MOYENNE PRIORIT√â - Niveau 3 (Am√©liorations qualit√©)

#### 8. Monitoring et Observabilit√© Limit√©s

**Manques:**
- Pas de m√©triques temps r√©el
- Pas d'alertes automatiques
- Logs basiques (erreurs Unicode)
- Pas de dashboards performance

---

#### 9. Tests Automatis√©s Absents

**Probl√®me:** Aucun test unitaire/int√©gration

**Risque:** R√©gressions lors des √©volutions

---

#### 10. Gestion Photos/Vid√©os Non Optimis√©e

**Probl√®me:**
- Stockage local uniquement
- Pas de compression
- Pas de CDN

**Impact:** Saturation disque avec 400 demandes/mois

---

## 3Ô∏è‚É£ PLAN D'AM√âLIORATION TECHNIQUE D√âTAILL√â

### Phase 1 - CRITIQUE (0-3 mois) - OBLIGATOIRE pour 400 demandes/mois

#### üéØ Objectif: Rendre le syst√®me robuste et persistant

#### Action 1.1: Migration Base de Donn√©es PostgreSQL

**Impl√©mentation:**

1. **Cr√©er le sch√©ma de base de donn√©es:**

```sql
-- Tickets SAV
CREATE TABLE tickets (
    ticket_id VARCHAR(50) PRIMARY KEY,
    customer_id VARCHAR(100) NOT NULL,
    customer_name VARCHAR(200),
    order_number VARCHAR(50) NOT NULL,
    product_sku VARCHAR(100),
    product_name VARCHAR(200),
    problem_description TEXT NOT NULL,
    problem_category VARCHAR(50),
    priority VARCHAR(10),
    priority_score INTEGER,
    status VARCHAR(50),
    warranty_covered BOOLEAN,
    auto_resolved BOOLEAN,
    resolution_type VARCHAR(50),
    resolution_description TEXT,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    INDEX idx_order (order_number),
    INDEX idx_customer (customer_id),
    INDEX idx_status (status),
    INDEX idx_created (created_at)
);

-- Historique des actions
CREATE TABLE ticket_actions (
    action_id SERIAL PRIMARY KEY,
    ticket_id VARCHAR(50) REFERENCES tickets(ticket_id),
    timestamp TIMESTAMP DEFAULT NOW(),
    actor VARCHAR(100),
    action_type VARCHAR(50),
    description TEXT,
    metadata JSONB
);

-- Sessions chat
CREATE TABLE chat_sessions (
    session_id VARCHAR(100) PRIMARY KEY,
    conversation_history JSONB,
    client_data JSONB,
    ticket_data JSONB,
    conversation_type VARCHAR(50),
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    expires_at TIMESTAMP
);

-- Preuves (photos/vid√©os)
CREATE TABLE evidences (
    evidence_id SERIAL PRIMARY KEY,
    ticket_id VARCHAR(50) REFERENCES tickets(ticket_id),
    evidence_type VARCHAR(20),
    file_url VARCHAR(500),
    file_size BIGINT,
    quality_score FLOAT,
    uploaded_at TIMESTAMP DEFAULT NOW()
);
```

2. **Modifier sav_workflow_engine.py:**

```python
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker

class SAVWorkflowEngine:
    def __init__(self, db_session: AsyncSession):
        self.db = db_session
        # ‚ùå SUPPRIMER: self.active_tickets = {}

    async def process_new_claim(self, ...):
        # Cr√©er ticket en base de donn√©es
        ticket_db = TicketDB(
            ticket_id=ticket_id,
            customer_id=customer_id,
            # ... autres champs
        )
        self.db.add(ticket_db)
        await self.db.commit()
        return ticket_db

    async def get_ticket(self, ticket_id: str):
        result = await self.db.execute(
            select(TicketDB).where(TicketDB.ticket_id == ticket_id)
        )
        return result.scalar_one_or_none()
```

3. **Ajouter SQLAlchemy models:**

```python
# backend/app/models/database.py
from sqlalchemy import Column, String, Integer, Boolean, Text, TIMESTAMP
from sqlalchemy.ext.declarative import declarative_base

Base = declarative_base()

class TicketDB(Base):
    __tablename__ = 'tickets'

    ticket_id = Column(String(50), primary_key=True)
    customer_id = Column(String(100), nullable=False)
    # ... autres colonnes
```

**Dur√©e:** 2-3 semaines
**Priorit√©:** üî¥ CRITIQUE
**Co√ªt:** Migration simple, pas de co√ªt suppl√©mentaire

---

#### Action 1.2: Impl√©menter Redis pour Sessions

**Impl√©mentation:**

```python
# backend/app/services/session_manager.py
import redis.asyncio as redis
import json

class SessionManager:
    def __init__(self):
        self.redis = redis.from_url("redis://localhost:6379")

    async def save_session(self, session_id: str, chatbot_state: dict):
        await self.redis.setex(
            f"session:{session_id}",
            3600,  # 1 heure TTL
            json.dumps(chatbot_state)
        )

    async def load_session(self, session_id: str) -> dict:
        data = await self.redis.get(f"session:{session_id}")
        return json.loads(data) if data else None
```

**Modifier chat.py:**

```python
session_manager = SessionManager()

@router.post("/", response_model=ChatResponse)
async def chat(request: ChatRequest):
    # Charger session depuis Redis
    session_data = await session_manager.load_session(request.session_id)

    if session_data:
        chatbot = MeubledeFranceChatbot.from_dict(session_data, api_key)
    else:
        chatbot = MeubledeFranceChatbot(api_key=api_key)

    result = await chatbot.chat(...)

    # Sauvegarder session dans Redis
    await session_manager.save_session(request.session_id, chatbot.to_dict())
```

**Dur√©e:** 1 semaine
**Priorit√©:** üî¥ CRITIQUE
**Co√ªt:** Redis gratuit (local) ou $10-20/mois (cloud)

---

#### Action 1.3: Gestion d'Erreurs et Retry Automatique

```python
from tenacity import retry, stop_after_attempt, wait_exponential

class MeubledeFranceChatbot:
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10)
    )
    async def _call_openai(self, messages):
        try:
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=messages,
                temperature=0.7,
                max_tokens=1500  # Limite pour contr√¥ler co√ªts
            )
            return response
        except openai.RateLimitError:
            logger.warning("Quota OpenAI d√©pass√©, retry dans 10s...")
            raise
        except openai.APIError as e:
            logger.error(f"Erreur API OpenAI: {e}")
            # Fallback vers r√©ponse g√©n√©rique
            return self._generate_fallback_response()
```

**Dur√©e:** 3-4 jours
**Priorit√©:** üî¥ CRITIQUE

---

#### Action 1.4: Optimisation Co√ªts OpenAI

**Strat√©gie Hybrid GPT-4 / GPT-3.5:**

```python
def select_model(self, user_message: str, conversation_type: str) -> str:
    """Choisir le mod√®le selon la complexit√©"""

    # Messages simples ‚Üí GPT-3.5 ($0.002/1K tokens)
    simple_patterns = [
        "oui", "non", "merci", "bonjour",
        "continuer", "cl√¥turer"
    ]
    if any(p in user_message.lower() for p in simple_patterns):
        return "gpt-3.5-turbo"

    # Analyse SAV complexe ‚Üí GPT-4
    if conversation_type == "sav" and self.pending_ticket_validation:
        return "gpt-4"

    # Par d√©faut ‚Üí GPT-3.5
    return "gpt-3.5-turbo"
```

**√âconomie estim√©e:** 40-50% des co√ªts
**$60/mois ‚Üí $30-35/mois** pour 400 demandes

---

### Phase 2 - HAUTE PRIORIT√â (3-6 mois) - Performance et Scale

#### Action 2.1: Load Balancing avec Nginx

```nginx
upstream fastapi_backend {
    server 127.0.0.1:8001;
    server 127.0.0.1:8002;
    server 127.0.0.1:8003;
}

server {
    listen 80;

    location /api/ {
        proxy_pass http://fastapi_backend;
        proxy_set_header Host $host;
    }
}
```

**D√©ploiement:** 3 instances FastAPI
**Capacit√©:** 150 requ√™tes simultan√©es
**Dur√©e:** 1 semaine

---

#### Action 2.2: Mise en Cache avec Redis

```python
from functools import lru_cache

class OrderDataService:
    @cache_with_ttl(ttl=300)  # 5 minutes
    async def fetch_order_data(self, order_number: str):
        # V√©rifier cache Redis
        cached = await redis.get(f"order:{order_number}")
        if cached:
            return json.loads(cached)

        # Sinon, fetch depuis source
        data = await self._fetch_from_source(order_number)

        # Mettre en cache
        await redis.setex(
            f"order:{order_number}",
            300,
            json.dumps(data)
        )
        return data
```

**Gain:** R√©duction de 70% des appels externes
**Dur√©e:** 1 semaine

---

#### Action 2.3: S√©curit√© et Rate Limiting

```python
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@router.post("/")
@limiter.limit("10/minute")  # Max 10 requ√™tes/minute par IP
async def chat(request: ChatRequest):
    # ... code existant
```

**Protection contre:**
- Abus du syst√®me
- Attaques DDoS
- √âpuisement quota OpenAI

**Dur√©e:** 3-4 jours

---

#### Action 2.4: Stockage Photos sur S3/Cloud

```python
import boto3

class FileStorage:
    def __init__(self):
        self.s3 = boto3.client('s3')
        self.bucket = 'meuble-de-france-sav'

    async def upload_evidence(self, file, ticket_id):
        # Compresser l'image
        compressed = await self.compress_image(file)

        # Upload vers S3
        key = f"evidences/{ticket_id}/{file.filename}"
        self.s3.upload_fileobj(compressed, self.bucket, key)

        # Retourner URL CDN
        return f"https://cdn.meuble-de-france.fr/{key}"
```

**Co√ªt:** ~$5-10/mois pour 400 demandes
**Dur√©e:** 1 semaine

---

### Phase 3 - MOYENNE PRIORIT√â (6-12 mois) - Monitoring et Tests

#### Action 3.1: Monitoring avec Prometheus + Grafana

```python
from prometheus_client import Counter, Histogram

chat_requests = Counter('chat_requests_total', 'Total chat requests')
chat_duration = Histogram('chat_duration_seconds', 'Chat processing time')

@router.post("/")
async def chat(request: ChatRequest):
    chat_requests.inc()

    with chat_duration.time():
        result = await chatbot.chat(...)

    return result
```

**M√©triques surveill√©es:**
- Nombre de demandes/heure
- Temps de r√©ponse moyen
- Taux d'erreur OpenAI
- Co√ªts OpenAI en temps r√©el

**Dur√©e:** 1 semaine

---

#### Action 3.2: Tests Automatis√©s

```python
# tests/test_sav_workflow.py
import pytest

@pytest.mark.asyncio
async def test_ticket_creation():
    engine = SAVWorkflowEngine(db_session)

    ticket = await engine.process_new_claim(
        customer_id="test@example.com",
        order_number="CMD-2024-12345",
        problem_description="Pied cass√©",
        # ...
    )

    assert ticket.ticket_id is not None
    assert ticket.priority in ["P0", "P1", "P2", "P3"]
```

**Couverture cible:** 80%
**Dur√©e:** 2-3 semaines

---

## 4Ô∏è‚É£ STRAT√âGIE D'√âVOLUTIVIT√â 2-3 ANS

### Roadmap d'√âvolution

```
ANN√âE 1 (2025-2026): Consolidation
‚îú‚îÄ Q1: Phase 1 CRITIQUE (DB + Redis + Retry)
‚îú‚îÄ Q2: Phase 2 PERFORMANCE (Load Balancing + Cache)
‚îú‚îÄ Q3: Phase 3 MONITORING (Prometheus + Tests)
‚îî‚îÄ Q4: Optimisation continue
        Capacit√©: 400-500 demandes/mois ‚úÖ

ANN√âE 2 (2026-2027): Expansion
‚îú‚îÄ Q1: Multi-canal (SMS, Email, WhatsApp)
‚îú‚îÄ Q2: IA pr√©dictive (anticiper probl√®mes)
‚îú‚îÄ Q3: Int√©gration CRM/ERP
‚îî‚îÄ Q4: Analytics avanc√©s
        Capacit√©: 800-1000 demandes/mois ‚úÖ

ANN√âE 3 (2027-2028): Intelligence
‚îú‚îÄ Q1: ML pour d√©tection automatique
‚îú‚îÄ Q2: Recommandations personnalis√©es
‚îú‚îÄ Q3: Self-service avanc√©
‚îî‚îÄ Q4: Automatisation 90%+
        Capacit√©: 1500+ demandes/mois ‚úÖ
```

### Architecture Cible (2-3 ans)

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Load Balancer  ‚îÇ
                    ‚îÇ    (Nginx)      ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚ñº                ‚ñº                ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  FastAPI #1  ‚îÇ ‚îÇ  FastAPI #2  ‚îÇ ‚îÇ  FastAPI #3  ‚îÇ
    ‚îÇ   (8001)     ‚îÇ ‚îÇ   (8002)     ‚îÇ ‚îÇ   (8003)     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                ‚îÇ                ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                   ‚îÇ                   ‚îÇ
        ‚ñº                   ‚ñº                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PostgreSQL  ‚îÇ    ‚îÇ    Redis     ‚îÇ    ‚îÇ   OpenAI     ‚îÇ
‚îÇ  (Primary)   ‚îÇ    ‚îÇ  (Sessions   ‚îÇ    ‚îÇ   GPT-4/3.5  ‚îÇ
‚îÇ              ‚îÇ    ‚îÇ   + Cache)   ‚îÇ    ‚îÇ              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚îÇ R√©plication
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PostgreSQL  ‚îÇ
‚îÇ  (Replica)   ‚îÇ
‚îÇ  (Read-only) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Prometheus  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∫ Grafana (Dashboards)
‚îÇ  (Metrics)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### √âvolution des Canaux

**Phase 1 (Actuel):** Web uniquement

**Phase 2 (An 2):**
```python
class MultiChannelBot:
    async def handle_message(self, message, channel):
        if channel == "web":
            return await self.web_handler(message)
        elif channel == "sms":
            return await self.sms_handler(message)
        elif channel == "whatsapp":
            return await self.whatsapp_handler(message)
        elif channel == "email":
            return await self.email_handler(message)
```

**Canaux pr√©vus:**
- ‚úÖ Web (actuel)
- üì± SMS (Twilio API)
- üí¨ WhatsApp Business API
- üìß Email (IMAP/SMTP)
- üìû T√©l√©phone (IVR avec Twilio)

---

## 5Ô∏è‚É£ RECOMMANDATIONS HAUTE DISPONIBILIT√â

### Objectif: 99.9% Uptime (8.76 heures downtime/an max)

#### 1. Infrastructure Redondante

**Configuration recommand√©e:**

```yaml
# docker-compose.yml
version: '3.8'

services:
  fastapi-1:
    image: meuble-sav-backend
    environment:
      - INSTANCE_ID=1
    depends_on:
      - postgres
      - redis

  fastapi-2:
    image: meuble-sav-backend
    environment:
      - INSTANCE_ID=2
    depends_on:
      - postgres
      - redis

  fastapi-3:
    image: meuble-sav-backend
    environment:
      - INSTANCE_ID=3
    depends_on:
      - postgres
      - redis

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    depends_on:
      - fastapi-1
      - fastapi-2
      - fastapi-3

  postgres:
    image: postgres:15
    volumes:
      - postgres-data:/var/lib/postgresql/data
    environment:
      POSTGRES_DB: meuble_sav
      POSTGRES_USER: sav_user
      POSTGRES_PASSWORD: ${DB_PASSWORD}

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
```

---

#### 2. Backup Automatis√©

```bash
# backup-script.sh
#!/bin/bash

# Backup PostgreSQL
pg_dump -h localhost -U sav_user meuble_sav | gzip > \
  backups/meuble_sav_$(date +%Y%m%d_%H%M%S).sql.gz

# Backup Redis
redis-cli --rdb backups/redis_$(date +%Y%m%d_%H%M%S).rdb

# Upload vers S3
aws s3 sync backups/ s3://meuble-backups/sav/

# Garder 30 jours de backups
find backups/ -mtime +30 -delete
```

**Fr√©quence:** Toutes les 6 heures
**R√©tention:** 30 jours

---

#### 3. Health Checks et Auto-Recovery

```python
# backend/app/main.py

@app.get("/health")
async def health_check():
    checks = {
        "database": await check_database(),
        "redis": await check_redis(),
        "openai": await check_openai_quota()
    }

    all_healthy = all(checks.values())

    return JSONResponse(
        status_code=200 if all_healthy else 503,
        content={
            "status": "healthy" if all_healthy else "unhealthy",
            "checks": checks,
            "timestamp": datetime.now().isoformat()
        }
    )
```

**Monitoring externe:** UptimeRobot ou StatusCake
**Auto-restart:** Docker avec `restart: always`

---

#### 4. Alertes Automatiques

```python
# alerts.py
import smtplib

class AlertManager:
    def alert_critical(self, message):
        # Email
        self.send_email("admin@meuble-de-france.fr", message)

        # SMS (Twilio)
        self.send_sms("+33612345678", message)

        # Slack
        self.send_slack_notification(message)

    def trigger_conditions(self):
        if error_rate > 10%:
            self.alert_critical("Taux d'erreur √©lev√©!")

        if response_time_avg > 5s:
            self.alert_critical("Temps de r√©ponse d√©grad√©!")

        if openai_quota < 10%:
            self.alert_critical("Quota OpenAI presque √©puis√©!")
```

---

#### 5. Plan de Reprise d'Activit√© (DRP)

**RTO (Recovery Time Objective):** 30 minutes
**RPO (Recovery Point Objective):** 6 heures

**Proc√©dure de restauration:**

1. **D√©tecter la panne** (< 5 min)
   - Alertes automatiques
   - Health checks

2. **Analyser la cause** (< 10 min)
   - V√©rifier logs Grafana
   - Identifier composant d√©faillant

3. **Restaurer le service** (< 15 min)
   - Red√©marrer conteneurs Docker
   - Basculer sur instance de backup
   - Restaurer DB depuis backup si n√©cessaire

---

## 6Ô∏è‚É£ ESTIMATION BUDG√âTAIRE

### Co√ªts Mensuels Actuels (200 demandes/mois)

| Poste | Co√ªt |
|-------|------|
| Serveur (1 instance) | $10-20 |
| OpenAI GPT-4 | $30 |
| **TOTAL** | **$40-50/mois** |

### Co√ªts Mensuels Projet√©s (400 demandes/mois) - Apr√®s Optimisations

| Poste | Co√ªt |
|-------|------|
| Serveur (3 instances) | $30-50 |
| PostgreSQL (managed) | $20-30 |
| Redis (managed) | $10-20 |
| OpenAI Hybrid GPT-4/3.5 | $35-40 |
| S3 Stockage Photos | $5-10 |
| Monitoring (Grafana Cloud) | $15 |
| Backups | $5 |
| **TOTAL** | **$120-165/mois** |

### Co√ªts de D√©veloppement (Phase 1-3)

| Phase | Dur√©e | Co√ªt Estim√© |
|-------|-------|-------------|
| Phase 1 - CRITIQUE | 3 mois | 40-60h dev |
| Phase 2 - PERFORMANCE | 3 mois | 30-40h dev |
| Phase 3 - MONITORING | 3 mois | 20-30h dev |
| **TOTAL** | **9 mois** | **90-130h dev** |

---

## 7Ô∏è‚É£ PLAN D'ACTION IMM√âDIAT (Next Steps)

### Priorit√© Imm√©diate (Semaine 1-2)

‚úÖ **√âtape 1:** Mettre en place PostgreSQL
- Cr√©er sch√©ma de base de donn√©es
- Migrer `sav_workflow_engine` vers DB
- Tester cr√©ation/lecture tickets

‚úÖ **√âtape 2:** Impl√©menter Redis pour sessions
- Configurer Redis
- Adapter `chatbot_instances` vers Redis
- Tester persistance sessions

‚úÖ **√âtape 3:** Ajouter retry automatique OpenAI
- Impl√©menter `tenacity`
- Tester gestion d'erreurs

### Court Terme (Mois 1)

‚úÖ **√âtape 4:** Optimiser co√ªts OpenAI
- Impl√©menter hybrid GPT-4/3.5
- Limiter tokens par requ√™te

‚úÖ **√âtape 5:** Backups automatis√©s
- Script backup PostgreSQL
- Cron job quotidien

### Moyen Terme (Mois 2-3)

‚úÖ **√âtape 6:** Load balancing
- Configurer Nginx
- D√©ployer 3 instances FastAPI

‚úÖ **√âtape 7:** Monitoring
- Prometheus + Grafana
- Alertes critiques

---

## 8Ô∏è‚É£ INDICATEURS DE SUCC√àS (KPIs)

### M√©triques Techniques

| M√©trique | Valeur Actuelle | Objectif 400 demandes/mois |
|----------|-----------------|----------------------------|
| **Uptime** | ~95% | 99.9% |
| **Temps r√©ponse moyen** | 3-5s | < 2s |
| **Taux d'erreur** | ~5% | < 1% |
| **Sessions simultan√©es** | 5-10 | 50+ |
| **Tickets stock√©s** | 50-100 | Illimit√© (DB) |
| **Co√ªt par demande** | $0.20 | $0.10 |

### M√©triques Business

| M√©trique | Objectif |
|----------|----------|
| **Taux de r√©solution automatique** | > 60% |
| **Satisfaction client** | > 85% |
| **Temps moyen de traitement** | < 48h |
| **Tickets escalad√©s** | < 30% |

---

## üìå CONCLUSION

### R√©sum√© des Actions Critiques

üî¥ **URGENT - √Ä faire IMM√âDIATEMENT:**
1. Migration PostgreSQL (tickets persistants)
2. Redis pour sessions
3. Retry automatique OpenAI

üü† **IMPORTANT - 1-3 mois:**
4. Load balancing (3 instances)
5. Cache Redis pour donn√©es
6. Optimisation co√ªts OpenAI

üü° **SOUHAITABLE - 3-6 mois:**
7. Monitoring Prometheus/Grafana
8. Tests automatis√©s
9. Stockage S3

### Verdict Final

**Le chatbot SAV Meuble de France peut g√©rer 400 demandes/mois SEULEMENT si les 3 actions critiques (PostgreSQL, Redis, Retry) sont impl√©ment√©es dans les 2-3 prochains mois.**

**Sans ces am√©liorations, le syst√®me restera limit√© √† 150-250 demandes/mois avec un risque √©lev√© de perte de donn√©es.**

---

**Document g√©n√©r√© le:** 6 D√©cembre 2025
**Validit√©:** 12 mois
**Prochaine r√©vision:** Juin 2026
