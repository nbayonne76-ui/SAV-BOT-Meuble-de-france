# backend/app/api/endpoints/voice.py
"""
API endpoints pour le mode vocal avec Whisper + GPT + TTS
Utilise la configuration client personnalis√©e
"""
import logging
import tempfile
import os
from pathlib import Path
from typing import Optional
from datetime import datetime, timedelta
from fastapi import APIRouter, UploadFile, File, HTTPException, Form
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from openai import OpenAI
import httpx

from app.core.config import settings
from app.core.chatbot_config import config as chatbot_config
from app.core.circuit_breaker import CircuitBreakerManager, CircuitBreakerError
from app.services.sav_workflow_engine import sav_workflow_engine
from app.services.warranty_service import warranty_service
from app.models.warranty import WarrantyType
from app.services.voice_emotion_detector import get_voice_emotion_detector

router = APIRouter()
logger = logging.getLogger(__name__)

# Initialize OpenAI client avec configuration pour r√©seau d'entreprise
# D√©sactive la v√©rification SSL pour fonctionner derri√®re un proxy d'entreprise
# Note: verify=False est n√©cessaire pour les r√©seaux d'entreprise avec interception SSL
http_client = httpx.Client(verify=False, timeout=30.0)
client = OpenAI(
    api_key=settings.OPENAI_API_KEY,
    http_client=http_client
)

logger.info("üåê Client OpenAI configur√© pour r√©seau d'entreprise (SSL verification d√©sactiv√©e)")


def extract_ticket_data_from_recap(recap_text: str) -> dict:
    """
    Extrait les donn√©es du ticket depuis le r√©capitulatif

    Format attendu:
    Nom: [nom]
    Probl√®me: [probl√®me]
    Produit: [produit]
    Commande: [commande]
    """
    import re

    data = {
        "customer_name": None,
        "problem_description": None,
        "product": None,
        "order_number": None
    }

    # Extraire le nom
    nom_match = re.search(r"Nom:\s*(.+?)(?:\n|$)", recap_text, re.IGNORECASE)
    if nom_match:
        data["customer_name"] = nom_match.group(1).strip()

    # Extraire le probl√®me
    problem_match = re.search(r"Probl√®me:\s*(.+?)(?:\n|$)", recap_text, re.IGNORECASE | re.MULTILINE)
    if problem_match:
        data["problem_description"] = problem_match.group(1).strip()

    # Extraire le produit
    product_match = re.search(r"Produit:\s*(.+?)(?:\n|$)", recap_text, re.IGNORECASE)
    if product_match:
        data["product"] = product_match.group(1).strip()

    # Extraire le num√©ro de commande
    cmd_match = re.search(r"Commande:\s*(.+?)(?:\n|$)", recap_text, re.IGNORECASE)
    if cmd_match:
        data["order_number"] = cmd_match.group(1).strip()

    return data


def extract_collected_info_from_history(conversation_history: list[dict], current_message: str) -> dict:
    """
    Analyse l'historique de conversation pour extraire les informations d√©j√† collect√©es

    Returns un dict avec les informations trouv√©es (customer_name, problem, product, order_number)
    """
    import re

    collected = {
        "customer_name": None,
        "problem": None,
        "product": None,
        "order_number": None
    }

    # Analyser tous les messages utilisateur (historique + message actuel)
    all_user_messages = []
    for msg in conversation_history:
        if msg.get("role") == "user":
            all_user_messages.append(msg.get("content", ""))
    all_user_messages.append(current_message)

    full_text = " ".join(all_user_messages)

    # D√©tecter le num√©ro de commande (patterns multiples: avec ou sans tirets)
    cmd_patterns = [
        r"CMD[\s-]*(\d{4})[\s-]*(\d+)[\s-]*(\d+)[\s-]*(\d+)",  # CMD 2025 30 301 25 10 ou CMD-2025-3030125-10
        r"commande\s+(\d+)",  # "commande 12345"
    ]
    for pattern in cmd_patterns:
        cmd_match = re.search(pattern, full_text, re.IGNORECASE)
        if cmd_match:
            if len(cmd_match.groups()) == 4:
                # Reformater au format standard CMD-YYYY-XXXXX
                collected["order_number"] = f"CMD-{cmd_match.group(1)}-{cmd_match.group(2)}{cmd_match.group(3)}{cmd_match.group(4)}"
            else:
                collected["order_number"] = cmd_match.group(1)
            break

    # D√©tecter le nom (chercher dans tous les messages utilisateur)
    for content in all_user_messages:
        # Pattern: "je m'appelle X" ou "c'est X" ou "je suis X"
        name_match = re.search(r"(?:je m'appelle|c'est|je suis)\s+([A-Z][a-z√©√®√™√†√¢√¥√Æ√π]+(?:\s+[A-Z][a-z√©√®√™√†√¢√¥√Æ√π]+)+)", content, re.IGNORECASE)
        if name_match:
            collected["customer_name"] = name_match.group(1).strip().title()
            break
        # Pattern: Nom Pr√©nom au d√©but du message
        if not collected["customer_name"]:
            first_words = content.split()[:3]
            if len(first_words) >= 2:
                potential_name = " ".join(first_words[:2])
                if re.match(r"^[A-Z][a-z√©√®√™√†√¢√¥√Æ√π]+\s+[A-Z][a-z√©√®√™√†√¢√¥√Æ√π]+$", potential_name, re.IGNORECASE):
                    collected["customer_name"] = potential_name.title()

    # D√©tecter le produit (chercher mentions de meubles)
    product_keywords = ["canap√©", "table", "fauteuil", "lit", "armoire", "chaise", "bureau", "meuble", "commode"]
    for keyword in product_keywords:
        if keyword in full_text.lower():
            # Chercher si un mod√®le suit
            model_match = re.search(rf"{keyword}\s+([A-Z][A-Z0-9]+)", full_text, re.IGNORECASE)
            if model_match:
                collected["product"] = f"{keyword.capitalize()} {model_match.group(1).upper()}"
            else:
                # Juste le type de meuble sans mod√®le
                collected["product"] = keyword.capitalize()
            break

    # D√©tecter le probl√®me (chercher mots-cl√©s de probl√®me dans tous les messages)
    problem_keywords = ["cass√©", "d√©chir√©", "ray√©", "grince", "mal align√©", "d√©fectueux", "ab√Æm√©", "rayure", "fissur√©", "trou√©"]
    for content in all_user_messages:
        content_lower = content.lower()
        for keyword in problem_keywords:
            if keyword in content_lower:
                # Prendre la phrase qui contient le mot-cl√©
                sentences = re.split(r'[.!?,]', content)
                for sentence in sentences:
                    if keyword in sentence.lower():
                        collected["problem"] = sentence.strip()
                        break
                break
        if collected["problem"]:
            break

    return collected


class VoiceTranscriptionResponse(BaseModel):
    """Response model for voice transcription"""
    text: str
    language: Optional[str] = None
    duration: Optional[float] = None


class ChatRequest(BaseModel):
    """Request model for chat with conversation history"""
    message: str
    conversation_history: list[dict] = []
    session_id: Optional[str] = None
    photos: list[str] = []  # URLs des photos upload√©es


class ChatResponse(BaseModel):
    """Response model for chat"""
    response: str
    session_id: str
    action: Optional[str] = None  # "create_ticket" si le client a confirm√©
    ticket_data: Optional[dict] = None  # Donn√©es extraites pour le ticket
    emotion_analysis: Optional[dict] = None  # Analyse emotionnelle du client


@router.post("/transcribe", response_model=VoiceTranscriptionResponse)
async def transcribe_audio(
    audio_file: UploadFile = File(..., description="Audio file (mp3, wav, webm, m4a, etc.)")
):
    """
    Transcrit un fichier audio en texte avec Whisper API

    Supporte tous les formats audio courants.
    Latence moyenne: 500-800ms selon la longueur de l'audio.
    """
    try:
        logger.info(f"üì• R√©ception audio: {audio_file.filename} ({audio_file.content_type})")

        # Lire le contenu du fichier
        audio_content = await audio_file.read()

        # Cr√©er un fichier temporaire
        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(audio_file.filename).suffix) as temp_file:
            temp_file.write(audio_content)
            temp_path = temp_file.name

        try:
            # Transcription avec Whisper with circuit breaker protection
            logger.info("üé§ Transcription avec Whisper...")

            # Get circuit breaker for OpenAI Whisper
            whisper_breaker = CircuitBreakerManager.get_breaker(
                name="openai-whisper",
                failure_threshold=5,
                recovery_timeout=60,
                timeout=30
            )

            async def call_whisper():
                with open(temp_path, "rb") as audio:
                    return client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio,
                        language="fr",  # Forcer le fran√ßais pour meilleure pr√©cision
                        response_format="verbose_json"
                    )

            try:
                transcript = await whisper_breaker.call(call_whisper)
                logger.info(f"‚úÖ Transcription: {transcript.text}")

                return VoiceTranscriptionResponse(
                    text=transcript.text,
                    language=transcript.language if hasattr(transcript, 'language') else "fr",
                    duration=transcript.duration if hasattr(transcript, 'duration') else None
                )

            except CircuitBreakerError as e:
                logger.error(f"Whisper circuit breaker is open: {e}")
                raise HTTPException(
                    status_code=503,
                    detail="Service de transcription temporairement indisponible. Veuillez r√©essayer dans quelques instants."
                )

        finally:
            # Nettoyer le fichier temporaire
            if os.path.exists(temp_path):
                os.unlink(temp_path)

    except Exception as e:
        logger.error(f"‚ùå Erreur transcription: {e}")
        logger.error(f"‚ùå Type d'erreur: {type(e).__name__}")
        logger.error(f"‚ùå D√©tails: {repr(e)}")
        import traceback
        logger.error(f"‚ùå Stack trace:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Erreur de transcription: {str(e)}")


@router.post("/chat", response_model=ChatResponse)
async def voice_chat(request: ChatRequest):
    """
    Obtenir une r√©ponse du chatbot SAV avec GPT-4

    Maintient l'historique de conversation pour un contexte coh√©rent.
    Latence moyenne: 300-600ms selon la complexit√©.
    """
    try:
        logger.info(f"üí¨ Message re√ßu: {request.message[:50]}...")
        logger.info(f"üì∏ Photos attach√©es: {len(request.photos)}")

        # Extraire les informations d√©j√† collect√©es depuis l'historique
        collected_info = extract_collected_info_from_history(request.conversation_history, request.message)
        logger.info(f"üìã Informations d√©j√† collect√©es: {collected_info}")

        # Construire un rappel des informations d√©j√† connues
        info_reminder = ""
        if any(collected_info.values()):
            info_reminder = "\n\nüîç INFORMATIONS D√âJ√Ä COLLECT√âES (NE PAS REDEMANDER):\n"
            if collected_info["customer_name"]:
                info_reminder += f"‚úÖ Nom du client: {collected_info['customer_name']}\n"
            if collected_info["problem"]:
                info_reminder += f"‚úÖ Probl√®me: {collected_info['problem']}\n"
            if collected_info["product"]:
                info_reminder += f"‚úÖ Produit: {collected_info['product']}\n"
            if collected_info["order_number"]:
                info_reminder += f"‚úÖ Num√©ro de commande: {collected_info['order_number']}\n"
            info_reminder += "\n‚ö†Ô∏è IMPORTANT: Ne redemande JAMAIS ces informations que tu as d√©j√† !"

        # Ajouter une indication si des photos ont √©t√© upload√©es
        if request.photos and len(request.photos) > 0:
            info_reminder += f"\n\nüì∏ ALERTE: {len(request.photos)} photo(s) vient/viennent d'√™tre upload√©e(s) !"
            info_reminder += "\n‚ö†Ô∏è TU DOIS MAINTENANT G√âN√âRER IMM√âDIATEMENT LE R√âCAPITULATIF (√âTAPE 2)!"

        # Instructions syst√®me pour le SAV vocal (configuration client personnalis√©e)
        system_message = {
            "role": "system",
            "content": f"""Assistant vocal SAV {chatbot_config.ENTREPRISE_NOM}.{info_reminder}

üé§ WORKFLOW SAV - MODE VOCAL (5 √âTAPES)

**√âTAPE 1Ô∏è‚É£ : √âCOUTE ACTIVE** (apr√®s que le client d√©crit son probl√®me)
D√®s que le client mentionne un probl√®me (pied cass√©, tache, rayure, etc.):

R√©ponse vocale COURTE:
"Je suis d√©sol√© d'entendre cela. Pourriez-vous uploader des photos du [probl√®me mentionn√©] via le bouton pr√©vu √† cet effet ? Cela permettra √† notre SAV de traiter votre demande rapidement."

‚ö†Ô∏è R√àGLES √âTAPE 1:
- Message COURT (2-3 lignes maximum)
- NE PAS demander le mod√®le exact, la couleur, la r√©f√©rence, etc.
- NE PAS poser d'autres questions
- Juste: empathie + demande d'upload de photos
- Apr√®s cette r√©ponse, ATTENDRE que le client uploade les photos

**√âTAPE 2Ô∏è‚É£ : R√âCAPITULATIF AUTOMATIQUE** (IMM√âDIATEMENT apr√®s r√©ception des photos)
‚ö†Ô∏è IMPORTANT: Le syst√®me d√©tecte automatiquement quand des photos sont upload√©es. NE PAS attendre que le client demande le r√©capitulatif.

D√®s que tu re√ßois des photos (le syst√®me te l'indique), G√âN√àRE IMM√âDIATEMENT ce r√©capitulatif:

"Parfait, merci pour ces photos. Je r√©capitule votre demande :

Nom : [Nom du client SI MENTIONN√â, sinon mettre "Non fourni"]
Num√©ro de commande : [CMD-XXXX SI MENTIONN√â, sinon mettre "Non fourni"]
Probl√®me signal√© : [Description EXACTE donn√©e par le client]
Photos : Re√ßues ‚úì

Est-ce que tout est correct ?"

‚ö†Ô∏è R√àGLES √âTAPE 2:
- G√âN√âRER AUTOMATIQUEMENT le r√©capitulatif d√®s que des photos sont d√©tect√©es
- Utiliser UNIQUEMENT les informations que le client a R√âELLEMENT donn√©es
- Si une info manque, mettre "Non fourni" dans le r√©capitulatif
- NE PAS demander les infos manquantes AVANT le r√©capitulatif
- TOUJOURS terminer par "Est-ce que tout est correct ?"

**√âTAPE 3Ô∏è‚É£ : VALIDATION VOCALE** (√©couter la r√©ponse du client)
Apr√®s avoir demand√© "Est-ce que tout est correct ?", √âCOUTER la r√©ponse:

‚úÖ SI CLIENT DIT OUI (d√©tecter: "Oui", "OK", "C'est correct", "Valid√©", "Parfait", "Tout est bon"):
‚Üí PASSER √Ä L'√âTAPE 4

‚ùå SI CLIENT DIT NON (d√©tecter: "Non", "Pas tout √† fait", "Il faut changer"):
‚Üí Demander: "Qu'est-ce qui doit √™tre modifi√© ?"
‚Üí √âcouter la correction
‚Üí REFAIRE le r√©capitulatif avec les corrections (RETOUR √âTAPE 2)

‚ö†Ô∏è R√àGLES √âTAPE 3:
- Bien √©couter la r√©ponse du client
- D√©tecter les confirmations positives vs n√©gatives
- Si n√©gatif, demander pr√©cis√©ment quoi corriger

**√âTAPE 4Ô∏è‚É£ : CR√âATION TICKET + NOUVELLE QUESTION** (apr√®s validation positive)
Une fois que le client a valid√© le r√©capitulatif:

R√©ponse vocale:
"Excellent ! Votre ticket SAV a √©t√© cr√©√© avec succ√®s. Vous recevrez un email de confirmation sous quelques instants √† l'adresse {chatbot_config.ENTREPRISE_EMAIL_SAV}.

Puis-je faire autre chose pour vous ?"

‚ö†Ô∏è R√àGLES √âTAPE 4:
- Confirmer la cr√©ation du ticket
- Informer de l'email de confirmation
- TOUJOURS demander si le client a besoin d'autre chose
- ATTENDRE la r√©ponse du client

**√âTAPE 5Ô∏è‚É£ : CONTINUATION OU FIN DE CONVERSATION**
Apr√®s avoir demand√© "Puis-je faire autre chose pour vous ?", √âCOUTER:

‚úÖ SI CLIENT DIT OUI (d√©tecter: "Oui", "J'ai une autre question", "Oui s'il vous pla√Æt"):
‚Üí R√©pondre: "Je vous √©coute, comment puis-je vous aider ?"
‚Üí CONTINUER la conversation (RETOUR √âTAPE 1 si nouveau probl√®me)

‚ùå SI CLIENT DIT NON ou AU REVOIR (d√©tecter: "Non", "C'est bon", "Merci", "Au revoir", "Non merci"):
‚Üí R√©pondre: "Merci d'avoir contact√© {chatbot_config.ENTREPRISE_NOM}. Bonne journ√©e !"
‚Üí FIN DE LA CONVERSATION

‚ö†Ô∏è R√àGLES √âTAPE 5:
- Si client a un nouveau probl√®me, recommencer depuis √âTAPE 1
- Si client dit non/au revoir, dire au revoir poliment et terminer
- TOUJOURS terminer par un message chaleureux

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚ö†Ô∏è R√àGLES G√âN√âRALES IMPORTANTES:
1. R√©ponses TR√àS COURTES (max {chatbot_config.MAX_TOKENS} tokens pour le vocal)
2. Ton professionnel mais chaleureux et empathique
3. UNE seule question √† la fois
4. NE JAMAIS demander des d√©tails non essentiels (couleur, mod√®le exact, etc.)
5. RESPECTER STRICTEMENT les 5 √©tapes dans l'ordre
6. Apr√®s √âTAPE 4, TOUJOURS demander si le client a besoin d'autre chose
7. La conversation ne se termine QUE si le client dit au revoir apr√®s l'√âTAPE 5"""
        }

        # Construire l'historique des messages
        messages = [system_message]
        messages.extend(request.conversation_history)
        messages.append({"role": "user", "content": request.message})

        # Obtenir la r√©ponse avec le mod√®le configur√© with circuit breaker
        logger.info(f"ü§ñ G√©n√©ration de la r√©ponse avec {chatbot_config.MODELE_IA}...")

        # Get circuit breaker for OpenAI chat
        gpt_breaker = CircuitBreakerManager.get_breaker(
            name="openai-chat",
            failure_threshold=5,
            recovery_timeout=60,
            timeout=30
        )

        async def call_gpt():
            return client.chat.completions.create(
                model=chatbot_config.MODELE_IA,  # gpt-3.5-turbo (configur√© par le client)
                messages=messages,
                temperature=chatbot_config.TEMPERATURE,
                max_tokens=chatbot_config.MAX_TOKENS,  # 300 tokens (~300 mots, r√©ponses courtes)
                presence_penalty=0.6,
                frequency_penalty=0.3
            )

        try:
            completion = await gpt_breaker.call(call_gpt)
            response_text = completion.choices[0].message.content
            logger.info(f"‚úÖ R√©ponse: {response_text}")

        except CircuitBreakerError as e:
            logger.error(f"OpenAI chat circuit breaker is open: {e}")
            raise HTTPException(
                status_code=503,
                detail="Service de chat temporairement indisponible. Veuillez r√©essayer dans quelques instants."
            )

        # Analyze emotion from the user's message
        emotion_detector = get_voice_emotion_detector()
        emotion_analysis = await emotion_detector.analyze_emotion(
            transcript=request.message,
            conversation_history=request.conversation_history
        )
        logger.info(f"Emotion analysis: {emotion_analysis['emotion']} (confidence: {emotion_analysis['confidence']:.2f})")

        # D√©tecter l'action et extraire les donn√©es du ticket
        action = None
        ticket_data = None

        # Si c'est un r√©capitulatif, extraire les donn√©es du ticket pour validation
        if "Je r√©capitule" in response_text or "recapitule" in response_text.lower():
            action = "recap"
            ticket_data = extract_ticket_data_from_recap(response_text)
            logger.info(f"üìã R√©capitulatif - Donn√©es extraites: {ticket_data}")

        # Si c'est une confirmation de cr√©ation de ticket
        elif "ticket SAV est cr√©√©" in response_text or "Votre ticket est cr√©√©" in response_text:
            action = "create_ticket"

            # Extraire les donn√©es du r√©capitulatif depuis l'historique
            # Chercher le dernier message contenant "Je r√©capitule"
            for msg in reversed(request.conversation_history):
                if msg.get("role") == "assistant" and "Je r√©capitule" in msg.get("content", ""):
                    recap = msg.get("content", "")
                    ticket_data = extract_ticket_data_from_recap(recap)
                    logger.info(f"üìã Donn√©es du ticket extraites: {ticket_data}")
                    break

        return ChatResponse(
            response=response_text,
            session_id=request.session_id or "default",
            action=action,
            ticket_data=ticket_data,
            emotion_analysis=emotion_analysis
        )

    except Exception as e:
        logger.error(f"‚ùå Erreur chat: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur de g√©n√©ration de r√©ponse: {str(e)}")


@router.post("/speak")
async def text_to_speech(
    text: str = Form(..., description="Text to convert to speech"),
    voice: str = Form("nova", description="Voice: alloy, echo, fable, onyx, nova, shimmer")
):
    """
    Convertit du texte en audio avec TTS API

    Voix disponibles: alloy, echo, fable, onyx, nova (recommand√©e), shimmer
    Format de sortie: MP3
    Latence moyenne: 400-700ms selon la longueur du texte.
    """
    try:
        logger.info(f"üîä Synth√®se vocale: {text[:50]}... (voice: {voice})")

        # G√©n√©rer l'audio avec TTS with circuit breaker protection
        tts_breaker = CircuitBreakerManager.get_breaker(
            name="openai-tts",
            failure_threshold=5,
            recovery_timeout=60,
            timeout=30
        )

        async def call_tts():
            return client.audio.speech.create(
                model="tts-1",  # tts-1 est plus rapide, tts-1-hd est meilleure qualit√©
                voice=voice,
                input=text,
                response_format="mp3",
                speed=1.3  # Vitesse moyennement rapide pour meilleure exp√©rience utilisateur
            )

        try:
            response = await tts_breaker.call(call_tts)
            logger.info("‚úÖ Audio g√©n√©r√©")

            # Streamer l'audio directement
            return StreamingResponse(
                iter([response.content]),
                media_type="audio/mpeg",
                headers={
                    "Content-Disposition": "inline; filename=speech.mp3"
                }
            )

        except CircuitBreakerError as e:
            logger.error(f"TTS circuit breaker is open: {e}")
            raise HTTPException(
                status_code=503,
                detail="Service de synth√®se vocale temporairement indisponible. Veuillez r√©essayer dans quelques instants."
            )

    except Exception as e:
        logger.error(f"‚ùå Erreur TTS: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur de synth√®se vocale: {str(e)}")


@router.get("/voices")
async def list_voices():
    """
    Liste les voix disponibles pour TTS
    """
    return {
        "voices": [
            {
                "id": "alloy",
                "name": "Alloy",
                "gender": "neutral",
                "description": "Voix neutre et claire"
            },
            {
                "id": "echo",
                "name": "Echo",
                "gender": "male",
                "description": "Voix masculine calme"
            },
            {
                "id": "fable",
                "name": "Fable",
                "gender": "neutral",
                "description": "Voix expressive"
            },
            {
                "id": "onyx",
                "name": "Onyx",
                "gender": "male",
                "description": "Voix masculine profonde"
            },
            {
                "id": "nova",
                "name": "Nova",
                "gender": "female",
                "description": "Voix f√©minine chaleureuse (recommand√©e pour SAV)"
            },
            {
                "id": "shimmer",
                "name": "Shimmer",
                "gender": "female",
                "description": "Voix f√©minine douce"
            }
        ],
        "recommended": "nova"
    }


class CreateTicketRequest(BaseModel):
    """Request model for creating a ticket from voice conversation"""
    customer_name: str
    problem_description: str
    product: str
    order_number: str
    conversation_transcript: Optional[str] = None
    photos: list[str] = []  # URLs des photos upload√©es
    emotion_analysis: Optional[dict] = None  # Analyse emotionnelle pour priorite automatique


@router.post("/create-ticket")
async def create_ticket_from_voice(request: CreateTicketRequest):
    """
    Cr√©e un ticket SAV depuis une conversation vocale

    Utilise l'API SAV existante pour cr√©er le ticket.
    """
    try:
        logger.info(f"üé´ Cr√©ation de ticket SAV pour {request.customer_name}")

        # Utiliser le nom du client comme customer_id si pas d'ID disponible
        customer_id = request.customer_name.replace(" ", "_").lower()

        # G√©n√©rer un SKU g√©n√©rique pour les produits du mode vocal
        product_sku = f"VOICE-PRODUCT-{request.order_number or 'UNKNOWN'}"

        # Dates par d√©faut (achat il y a 30 jours, livraison il y a 15 jours)
        purchase_date = datetime.now() - timedelta(days=30)
        delivery_date = datetime.now() - timedelta(days=15)

        # Cr√©er une garantie pour le produit
        warranty = await warranty_service.create_warranty(
            order_number=request.order_number or f"VOICE-{datetime.now().strftime('%Y%m%d%H%M%S')}",
            product_sku=product_sku,
            product_name=request.product,
            customer_id=customer_id,
            purchase_date=purchase_date,
            delivery_date=delivery_date,
            warranty_type=WarrantyType.STANDARD
        )

        # Cr√©er le ticket via le workflow SAV
        ticket = await sav_workflow_engine.process_new_claim(
            customer_id=customer_id,
            order_number=request.order_number or f"VOICE-{datetime.now().strftime('%Y%m%d%H%M%S')}",
            product_sku=product_sku,
            product_name=request.product,
            problem_description=request.problem_description,
            warranty=warranty,
            customer_tier="standard",
            product_value=0.0
        )

        # Ajouter le nom du client et la transcription au ticket
        ticket.customer_name = request.customer_name
        if request.conversation_transcript:
            # Ajouter une note avec la transcription
            if not hasattr(ticket, 'notes'):
                ticket.notes = []
            ticket.notes.append(f"Transcription de la conversation vocale:\n{request.conversation_transcript}")

        # Apply emotion-based priority if emotion analysis is provided
        if request.emotion_analysis:
            emotion = request.emotion_analysis.get("emotion", "calme")
            emotion_priority = request.emotion_analysis.get("priority", "P3")
            confidence = request.emotion_analysis.get("confidence", 0.0)
            indicators = request.emotion_analysis.get("indicators", [])

            # Override ticket priority based on emotion
            ticket.priority = emotion_priority
            ticket.voice_emotion = emotion
            ticket.voice_emotion_confidence = confidence
            ticket.voice_emotion_indicators = indicators

            logger.info(f"üéØ Priorite basee sur emotion: {emotion} -> {emotion_priority} (confiance: {confidence:.2f})")

            # Add note about emotion-based priority
            if not hasattr(ticket, 'notes'):
                ticket.notes = []
            emotion_note = (
                f"Priorite automatique basee sur analyse emotionnelle:\n"
                f"- Emotion detectee: {emotion}\n"
                f"- Confiance: {confidence:.0%}\n"
                f"- Priorite assignee: {emotion_priority}\n"
                f"- Indicateurs: {', '.join(indicators[:3])}"
            )
            ticket.notes.append(emotion_note)

        # Ajouter les photos upload√©es au ticket
        if request.photos:
            if not hasattr(ticket, 'attachments'):
                ticket.attachments = []
            ticket.attachments.extend(request.photos)
            logger.info(f"üì∏ {len(request.photos)} photo(s) attach√©e(s) au ticket")

        logger.info(f"‚úÖ Ticket SAV cr√©√©: {ticket.ticket_id}")

        response_data = {
            "success": True,
            "ticket_id": ticket.ticket_id,
            "message": "Ticket SAV cr√©√© avec succ√®s",
            "data": {
                "customer_name": request.customer_name,
                "problem_description": request.problem_description,
                "product_name": request.product,
                "order_number": request.order_number,
                "priority": ticket.priority,
                "status": ticket.status,
                "source": "voice_chat"
            }
        }

        # Include emotion analysis in response if available
        if request.emotion_analysis:
            response_data["data"]["emotion"] = {
                "detected": ticket.voice_emotion,
                "confidence": ticket.voice_emotion_confidence,
                "indicators": ticket.voice_emotion_indicators,
                "priority_assigned": ticket.priority
            }

        return response_data

    except Exception as e:
        logger.error(f"‚ùå Erreur cr√©ation ticket: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur de cr√©ation du ticket: {str(e)}")
